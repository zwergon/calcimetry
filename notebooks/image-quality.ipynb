{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7904e357-600b-4954-becd-6af29694c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8e15d34-45bb-44c1-adb8-8a5aa0e7c312",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getcwd() == '/work/home/ai.calcimetry/notebooks':\n",
    "    print('On the sandbox')\n",
    "    os.system('pip install -r ../requirements.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1267f5-505c-461e-96a7-07db71a3097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "import skimage as ski\n",
    "import cv2\n",
    "import torch\n",
    "import piq\n",
    "#import nvidia_smi\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "# local library of functions to connect to image server\n",
    "import calcimetry.use_server as server\n",
    "from calcimetry.mongo_api import MongoInfo, MongoAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd383904-2b00-4ab5-a347-2b38eedd4850",
   "metadata": {},
   "source": [
    "# Notebook to explore ideas for image metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3847b119-aae1-4a6e-b270-7cae3c23258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = server.init() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100a6b2c-838c-411f-902a-c5ab0340248c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code 200\n",
      "nombre de fichiers disponibles 2268\n"
     ]
    }
   ],
   "source": [
    "files = server.get_list(img_path)\n",
    "print(\"nombre de fichiers disponibles\", len(files))\n",
    "dirnames = []\n",
    "for i in range(len(files)):\n",
    "    dirnames.append(files[i].split('/')[4])\n",
    "    \n",
    "listdir = set(dirnames)\n",
    "realdir = []\n",
    "photo_not_in_dir = []\n",
    "for ldir in listdir:\n",
    "    if '.jpg' in ldir:\n",
    "        photo_not_in_dir.append(ldir)\n",
    "    else:\n",
    "        realdir.append(ldir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03e68a5f-468a-4cf3-b99f-96d8b3b8af38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/andra/calci_photos/REP2104/Photos/GTR2004-12_0017_REP2104_0065_0161.jpg'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8cd6971-8ab9-403e-98d6-41080a753d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedlist = sorted(realdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d389e9-0110-4fbb-9441-5f4e0be87fe2",
   "metadata": {},
   "source": [
    "### The variance of the Laplacian can be a measure of the sharpness of the image, or the focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b1ec17-7910-4c8e-a063-dae4ef343610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_of_laplacian(image):\n",
    "    # compute the Laplacian of the image and then return the focus\n",
    "    # measure, which is simply the variance of the Laplacian\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c241f6c-07e9-4b5a-b2c4-a903cfd6b7e1",
   "metadata": {},
   "source": [
    "### Magnitude of the gradient to get sharpness of edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a39df130-7794-4e78-9577-0152c665f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_magnitude(image):\n",
    "    #Get magnitude of gradient for given image\n",
    "    ddepth = cv2.CV_64F\n",
    "    dx = cv2.Sobel(image, ddepth, 1, 0)\n",
    "    dy = cv2.Sobel(image, ddepth, 0, 1)\n",
    "    mag = cv2.magnitude(dx, dy)\n",
    "    return mag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ab446-335e-4cb0-968c-ea3181bf144a",
   "metadata": {},
   "source": [
    "## Colour analysis\n",
    "https://towardsdatascience.com/building-an-image-color-analyzer-using-python-12de6b0acf74\n",
    "\n",
    "* First, we are using k-Means to cluster the top colors. Inside the function we are passing the value of how many clusters do we want to divide. Here is the documentation for K-Means clustering. After clustering we predict the colors that weigh the most — meaning getting the most area on the image.\n",
    "* Secondly, we are calling the Counter function. Counter creates a container to the elements as dictionary keys, and their volume is store as dictionary values. If you are not familiar with dictionaries, they store data in key: value pairs. They are like function, and when you pass in the “key,” you can “value” as a return. Then we are ordering the colors according to the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24f062d7-1996-46df-bfcd-83b5044cec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_image(raw_img):\n",
    "    modified_img = cv2.resize(raw_img, (900, 600), interpolation = cv2.INTER_AREA)\n",
    "    modified_img = modified_img.reshape(modified_img.shape[0]*modified_img.shape[1], 3)\n",
    "    return modified_img\n",
    "\n",
    "def color_analysis(img):\n",
    "    clf = KMeans(n_clusters = 5)  # 5 top colours\n",
    "    color_labels = clf.fit_predict(img)\n",
    "    center_colors = clf.cluster_centers_\n",
    "    counts = Counter(color_labels)\n",
    "    ordered_colors = [center_colors[i] for i in counts.keys()]\n",
    "    return ordered_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181d9586-0e2f-4bd8-ac57-33db2c8f551b",
   "metadata": {},
   "source": [
    "### Function to read a directory and return some metrics\n",
    "\n",
    "Bundle the metric calculation into one function. Add some Facebook metrics too: `piq` PyTorch Image Quality\n",
    "* https://github.com/photosynthesis-team/piq/blob/master/examples/image_metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "365ee20a-5032-452e-ae6f-ffe636af6d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_directory(dirname, allfiles, quiet=True):\n",
    "    \"\"\"\n",
    "    Function to read all images in a directory and return a data frame with image metrics\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    dirname\n",
    "        Name of directory to be read\n",
    "    allfiles\n",
    "        List of all files in the image server\n",
    "        \n",
    "    returns\n",
    "    -------\n",
    "    df\n",
    "        Pandas dataframe of image metrics\n",
    "    \n",
    "    \"\"\"\n",
    "    ImageId = []\n",
    "    Path = []\n",
    "    FileName = []\n",
    "    DrillName = []\n",
    "    Cote0 = []\n",
    "    Cote1 = []\n",
    "    PxSize = []\n",
    "    PySize = []\n",
    "    Focus = []\n",
    "    GradientMax = []\n",
    "    GradientSTD = []\n",
    "    Colour1 = []\n",
    "    Colour2 = []\n",
    "    Colour3 = []\n",
    "    Colour4 = []\n",
    "    Colour5 = []\n",
    "    BRISQUE_i = []\n",
    "    BRISQUE_l = []\n",
    "\n",
    "    for file in allfiles:\n",
    "        if dirname in file:\n",
    "            img = server.get_file(file, quiet)\n",
    "            #if img.size() > 89478485:\n",
    "            #    continue\n",
    "            l0 = file.split('/')[-1]\n",
    "            l1 = l0.split('.')[0]\n",
    "            l2 = l1.split('_')\n",
    "            if len(l2)<3:\n",
    "                continue\n",
    "            width, height = img.size\n",
    "            if width*height > 89478485:\n",
    "                print(f'Not enough memory to process image {file} with PyTorch on local ')\n",
    "            ImageId.append(0)\n",
    "            Path.append(file)\n",
    "            FileName.append(l0)\n",
    "            DrillName.append(l2[-3])\n",
    "            Cote0.append(l2[-2])\n",
    "            Cote1.append(l2[-1])\n",
    "            PxSize.append(width)\n",
    "            PySize.append(height)\n",
    "\n",
    "            # focus metric\n",
    "            gray = cv2.cvtColor(np.asarray(img), cv2.COLOR_BGR2GRAY)\n",
    "            Focus.append(variance_of_laplacian(gray))\n",
    "            \n",
    "            # Gradient metric\n",
    "            GradientMax.append(np.max(gradient_magnitude(gray)[:]))\n",
    "            GradientSTD.append(np.std(gradient_magnitude(gray)[:]))\n",
    "            \n",
    "            # Top five colours\n",
    "            try:\n",
    "                colours = color_analysis(prep_image(np.asarray(img)))\n",
    "                Colour1.append(colours[0])\n",
    "                Colour2.append(colours[1])\n",
    "                Colour3.append(colours[2])\n",
    "                Colour4.append(colours[3])\n",
    "                Colour5.append(colours[4])\n",
    "            except:\n",
    "                Colour1.append(np.nan)\n",
    "                Colour2.append(np.nan)\n",
    "                Colour3.append(np.nan)\n",
    "                Colour4.append(np.nan)\n",
    "                Colour5.append(np.nan)\n",
    "            \n",
    "            # pytorch image quality, use try, except loop to kep going if image is too large or does not conform\n",
    "            try:\n",
    "                x = torch.tensor(np.asarray(img)).permute(2, 0, 1)[None, ...] / 255.\n",
    "                if torch.cuda.is_available():\n",
    "                    # Move to GPU to make computaions faster\n",
    "                    # print(torch.cuda.is_available())\n",
    "                    x = x.cuda()\n",
    "                brisque_index: torch.Tensor = piq.brisque(x, data_range=1., reduction='none')\n",
    "                brisque_loss: torch.Tensor = piq.BRISQUELoss(data_range=1., reduction='none')(x)\n",
    "\n",
    "                BRISQUE_i.append(brisque_index.item())\n",
    "                BRISQUE_l.append(brisque_loss.item())\n",
    "            except Exception as e:\n",
    "                print(f'Error in PyTorch with image {file}\\n' + e)\n",
    "                BRISQUE_i.append(np.nan)\n",
    "                BRISQUE_l.append(np.nan)\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            del x\n",
    "\n",
    "\n",
    "    d = {'ImageId':ImageId, 'Path':Path, 'FileName':FileName, 'DrillName':DrillName,\n",
    "         'Cote0':Cote0, 'Cote1':Cote1, 'PxSize':PxSize, 'PySize':PySize, 'Focus':Focus,\n",
    "         'Gradient max':GradientMax, 'Gradient std':GradientSTD, 'Colour1':Colour1, 'Colour2':Colour2, 'Colour3':Colour3, \n",
    "         'Colour4':Colour4, 'Colour5':Colour5, 'BRISQUE index':BRISQUE_i, 'BRISQUE loss':BRISQUE_l}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b84bcda-6815-4be8-b62b-9b73b43dd4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_directory(sortedlist[3], files)\n",
    "df.sort_values('Cote0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa4de31-87a1-4e62-86a2-ad864760997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = server.get_file(df['Path'][df['BRISQUE index'].idxmax()])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcde116-b1d6-4a61-9b10-d4e85075c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = server.get_file(df['Path'][df['BRISQUE index'].idxmin()])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12befa4f-2775-4e75-95fa-7d317fcf73d5",
   "metadata": {},
   "source": [
    "### Plot by colour RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ab0eed-776c-4cf7-b90a-4c840a1a20d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfna = df.dropna()\n",
    "colours = dfna['Colour1'].values\n",
    "red = np.zeros((len(colours),))\n",
    "green = np.zeros((len(colours),))\n",
    "blue = np.zeros((len(colours),))\n",
    "for i,colour in enumerate(colours):\n",
    "    red[i] = colour[0]\n",
    "    green[i] = colour[1]\n",
    "    blue[i] = colour[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3074cef3-7fd6-49d2-a52b-d44977367851",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,5])\n",
    "plt.subplot(1,3,1)\n",
    "plt.scatter(dfna['BRISQUE index'], dfna['Gradient std'], c=dfna['Colour1']/255)\n",
    "plt.xlabel('BRISQUE index')\n",
    "plt.ylabel('Gradient std')\n",
    "plt.subplot(1,3,2)\n",
    "plt.scatter(dfna['BRISQUE index'], dfna['Gradient max'], c=dfna['Colour1']/255)\n",
    "plt.xlabel('BRISQUE index')\n",
    "plt.ylabel('Gradient max')\n",
    "plt.subplot(1,3,3)\n",
    "plt.scatter(dfna['BRISQUE index'], dfna['Focus'], c=dfna['Colour1']/255)\n",
    "plt.xlabel('BRISQUE index')\n",
    "plt.ylabel('Focus')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e716f6-8ab5-4ca1-a187-edca15bc2cc1",
   "metadata": {},
   "source": [
    "## Find the worst and best image by metrics\n",
    "\n",
    "Run the function on all photos in the server (ignoring the ones that don't compute, they get `NaN`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb67b524-3c0f-47e0-a941-987510381459",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "\n",
    "if os.path.isfile('./BRISQUE_data.pkl') == False:\n",
    "    \n",
    "    max_count = len(sortedlist)\n",
    "\n",
    "    f = IntProgress(min=0, max=max_count) # instantiate a progress bar\n",
    "    display(f) # display the bar\n",
    "    \n",
    "    for i, directory in enumerate(sortedlist):\n",
    "\n",
    "        #print(f'Going into {directory}, i={i}')\n",
    "        if i == 0:\n",
    "            df = read_directory(directory, files)\n",
    "        else:\n",
    "            _df = read_directory(directory, files)\n",
    "            df = pd.concat([df, _df])\n",
    "\n",
    "        \"\"\"\n",
    "        nvidia_smi.nvmlInit()\n",
    "        handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "        # card id 0 hardcoded here, there is also a call to get all available card ids, so we could iterate\n",
    "        info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "        print(\"Free memory:\", info.free)\n",
    "        nvidia_smi.nvmlShutdown()\n",
    "        \"\"\"\n",
    "        \n",
    "        f.value += 1  # update progress bar\n",
    "\n",
    "    df.to_pickle('./BRISQUE_data.pkl')\n",
    "else:\n",
    "    df = pd.read_pickle('./BRISQUE_data.pkl')\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bda9eb4-6983-44af-8ba8-6ca9d952823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfna = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9adfaa-5ce4-4403-b494-399faacfa81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,10])\n",
    "#ax = df.plot.scatter(x='BRISQUE index', y='Focus', c='DarkBlue')\n",
    "plt.subplot(121)\n",
    "ax = sns.scatterplot(data=dfna, x='BRISQUE index', y='Focus', hue='DrillName')\n",
    "plt.legend([],[], frameon=False)\n",
    "plt.subplot(122)\n",
    "#ax = df.plot.scatter(x='BRISQUE index', y='Focus', c='DarkBlue')\n",
    "ax = sns.scatterplot(data=dfna, x='BRISQUE index', y='Focus', hue='PxSize')\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49ba897-f212-463c-97fd-a704721f5f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = server.get_file(df['Path'][df['BRISQUE index'].idxmax()])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e99cda-4264-46ea-91c8-221e68ccacb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = server.get_file(df['Path'][df['BRISQUE index'].idxmin()])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141e83b9-67e9-4ad9-b61f-2c3ee6d6c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = server.get_file(df['Path'][df['Focus'].idxmax()])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd229e3-cca0-4bef-937d-3aa6cf211c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = server.get_file(df['Path'][df['Focus'].idxmin()])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de89fb8-89c4-4491-8404-256515925b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,5])\n",
    "plt.subplot(1,3,1)\n",
    "plt.scatter(dfna['BRISQUE index'], dfna['Gradient std'], c=dfna['Colour1']/255)\n",
    "plt.xlabel('BRISQUE index')\n",
    "plt.ylabel('Gradient std')\n",
    "plt.subplot(1,3,2)\n",
    "plt.scatter(dfna['BRISQUE index'], dfna['Gradient max'], c=dfna['Colour1']/255)\n",
    "plt.xlabel('BRISQUE index')\n",
    "plt.ylabel('Gradient max')\n",
    "plt.subplot(1,3,3)\n",
    "plt.scatter(dfna['BRISQUE index'], dfna['Focus'], c=dfna['Colour1']/255)\n",
    "plt.xlabel('BRISQUE index')\n",
    "plt.ylabel('Focus')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300563d5-d5e0-4d29-b4b1-20325cb2fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "five_worst_b = list(dfna.sort_values('BRISQUE index')['Path'][:5])\n",
    "five_worst_g = list(dfna.sort_values('Gradient std')['Path'][:5])\n",
    "five_worst_f = list(dfna.sort_values('Focus')['Path'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f8241-4635-4864-a9c0-0501861a4afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,20])\n",
    "for i in range(5):\n",
    "    plt.subplot(5,3,i*3+1)\n",
    "    img = server.get_file(five_worst_b[i], quiet=True)\n",
    "    plt.imshow(img)\n",
    "    plt.title(five_worst_b[i].split('/')[-1])\n",
    "    plt.subplot(5,3,i*3+2)\n",
    "    img = server.get_file(five_worst_g[i], quiet=True)\n",
    "    plt.imshow(img)\n",
    "    plt.title(five_worst_g[i].split('/')[-1])\n",
    "    plt.subplot(5,3,i*3+3)\n",
    "    img = server.get_file(five_worst_f[i], quiet=True)\n",
    "    plt.imshow(img)\n",
    "    plt.title(five_worst_f[i].split('/')[-1])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5effe80e-2843-4972-b14c-203f5e340cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "five_best_b = list(dfna.sort_values('BRISQUE index')['Path'][-5:])\n",
    "five_best_g = list(dfna.sort_values('Gradient std')['Path'][-5:])\n",
    "five_best_f = list(dfna.sort_values('Focus')['Path'][-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5bde3c-88d4-4fbc-8c01-0e4781628548",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,20])\n",
    "for i in range(5):\n",
    "    plt.subplot(5,3,i*3+1)\n",
    "    img = server.get_file(five_best_b[i], quiet=True)\n",
    "    plt.imshow(img)\n",
    "    plt.title(five_best_b[i].split('/')[-1])\n",
    "    plt.subplot(5,3,i*3+2)\n",
    "    img = server.get_file(five_best_g[i], quiet=True)\n",
    "    plt.imshow(img)\n",
    "    plt.title(five_best_g[i].split('/')[-1])\n",
    "    plt.subplot(5,3,i*3+3)\n",
    "    img = server.get_file(five_best_f[i], quiet=True)\n",
    "    plt.imshow(img)\n",
    "    plt.title(five_best_f[i].split('/')[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f580a82d-ee4e-400d-98df-ce3c171de991",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb517136-1ba8-4c34-ad53-467f9aaf73d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "87318e7f4a2d21b475c64cf8351be356b72610cdf56f3bee5650c23ac32e6f1c"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
