{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32a18abf-ec93-4fc9-9579-4ec228950175",
   "metadata": {},
   "source": [
    "# Calculation of image quality\n",
    "\n",
    "Will pull the ImageId from the MongoDB to then grab the associated image from the image server. Then calculate various quality metrics. Finally build a dataframe with the Image ID, and quality scores. Then push back the new info to MongoDB.\n",
    "\n",
    "`!ssh -f -N -L 27017:irlinv-tellus:27017 irlinv-tellus`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acaf2f6-b5b1-45af-9bf7-4cbd3665f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, sys\n",
    "import requests\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "import skimage as ski\n",
    "import cv2\n",
    "import torch\n",
    "import piq\n",
    "#import nvidia_smi\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "# local library of functions to connect to image server\n",
    "#import calcimetry.use_server as server\n",
    "from calcimetry.mongo_api import MongoInfo, MongoAPI\n",
    "from calcimetry.calcimetry_api import CalcimetryAPI\n",
    "\n",
    "# parameters where the database is stored, can obviously be distant.\n",
    "sandbox = False\n",
    "if os.getcwd() == '/work/home/ai.calcimetry/notebooks':\n",
    "    print('On the sandbox')\n",
    "    sandbox = True\n",
    "    HOST='irlinv-tellus'\n",
    "    PORT=27017\n",
    "else:\n",
    "    # ssh -f -N -L 27017:irlinv-tellus:27017 irlinv-tellus\n",
    "    HOST='localhost'\n",
    "    PORT=27017   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd163da-1fc8-4e34-be02-8bc09ccacb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_path = server.init()\n",
    "mongo_info = MongoInfo(host=HOST, port=PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0349da28-6654-4788-991d-bd6cdfba9fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with MongoAPI(mongo_info=mongo_info) as mongo_api:\n",
    "    doc = mongo_api.db['images'].find()\n",
    "    df = pd.DataFrame(list(doc))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01caa4b-7d02-47c2-91f9-9e59f117af9c",
   "metadata": {},
   "source": [
    "### The variance of the Laplacian can be a measure of the sharpness of the image, or the focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aad758b-2105-48c7-ab23-404db0f81b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_of_laplacian(image):\n",
    "    # compute the Laplacian of the image and then return the focus\n",
    "    # measure, which is simply the variance of the Laplacian\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd73ea-312f-4f61-a297-cf7aae8af2ac",
   "metadata": {},
   "source": [
    "### Magnitude of the gradient to get sharpness of edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fb002c-2aa7-4f15-8066-1e4785c77cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_magnitude(image):\n",
    "    #Get magnitude of gradient for given image\n",
    "    ddepth = cv2.CV_64F\n",
    "    dx = cv2.Sobel(image, ddepth, 1, 0)\n",
    "    dy = cv2.Sobel(image, ddepth, 0, 1)\n",
    "    mag = cv2.magnitude(dx, dy)\n",
    "    return mag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b2f31f-d305-4e97-902d-fd0d72ba36f5",
   "metadata": {},
   "source": [
    "## Colour analysis\n",
    "https://towardsdatascience.com/building-an-image-color-analyzer-using-python-12de6b0acf74\n",
    "\n",
    "* First, we are using k-Means to cluster the top colors. Inside the function we are passing the value of how many clusters do we want to divide. Here is the documentation for K-Means clustering. After clustering we predict the colors that weigh the most — meaning getting the most area on the image.\n",
    "* Secondly, we are calling the Counter function. Counter creates a container to the elements as dictionary keys, and their volume is store as dictionary values. If you are not familiar with dictionaries, they store data in key: value pairs. They are like function, and when you pass in the “key,” you can “value” as a return. Then we are ordering the colors according to the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b471088a-157e-45a8-8ee9-d923a3c3617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_image(raw_img):\n",
    "    modified_img = cv2.resize(raw_img, (900, 600), interpolation = cv2.INTER_AREA)\n",
    "    modified_img = modified_img.reshape(modified_img.shape[0]*modified_img.shape[1], 3)\n",
    "    return modified_img\n",
    "\n",
    "def color_analysis(img):\n",
    "    clf = KMeans(n_clusters = 5)  # 5 top colours\n",
    "    color_labels = clf.fit_predict(img)\n",
    "    center_colors = clf.cluster_centers_\n",
    "    counts = Counter(color_labels)\n",
    "    ordered_colors = [center_colors[i] for i in counts.keys()]\n",
    "    return ordered_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2642ea-c838-4f82-bea9-dad938d1f210",
   "metadata": {},
   "source": [
    "### From the dataframe caclulate some metrics\n",
    "\n",
    "Add some Facebook metrics too: `piq` PyTorch Image Quality\n",
    "* https://github.com/photosynthesis-team/piq/blob/master/examples/image_metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d2622-0eee-4940-98bd-2c442fa2ffc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Resolution = []\n",
    "Focus = []\n",
    "GradientMax = []\n",
    "GradientSTD = []\n",
    "Colour1 = []\n",
    "Colour2 = []\n",
    "Colour3 = []\n",
    "Colour4 = []\n",
    "Colour5 = []\n",
    "BRISQUE_i = []\n",
    "\n",
    "missing_images = []\n",
    "\n",
    "f = IntProgress(min=0, max=len(df)) # instantiate the bar\n",
    "display(f) # display the bar\n",
    "\n",
    "for ImageId in df['ImageId']:\n",
    "    \n",
    "    with CalcimetryAPI(mongo_info=mongo_info) as calcimetry_api:\n",
    "        img = calcimetry_api.read_image(ImageId)\n",
    "        \n",
    "        if img is not None:\n",
    "\n",
    "            # focus metric\n",
    "            gray = cv2.cvtColor(np.asarray(img.jpg), cv2.COLOR_BGR2GRAY)\n",
    "            Focus.append(variance_of_laplacian(gray))\n",
    "\n",
    "            # Gradient metric\n",
    "            GradientMax.append(np.max(gradient_magnitude(gray)[:]))\n",
    "            GradientSTD.append(np.std(gradient_magnitude(gray)[:]))\n",
    "\n",
    "            # Top five colours\n",
    "            try:\n",
    "                colours = color_analysis(prep_image(np.asarray(img.jpg)))\n",
    "                Colour1.append(colours[0])\n",
    "                Colour2.append(colours[1])\n",
    "                Colour3.append(colours[2])\n",
    "                Colour4.append(colours[3])\n",
    "                Colour5.append(colours[4])\n",
    "            except:\n",
    "                Colour1.append(np.nan)\n",
    "                Colour2.append(np.nan)\n",
    "                Colour3.append(np.nan)\n",
    "                Colour4.append(np.nan)\n",
    "                Colour5.append(np.nan)\n",
    "\n",
    "            if sandbox == True:\n",
    "            # pytorch image quality, use try, except loop to keep going if image is too large or does not conform\n",
    "                try:\n",
    "                    x = torch.tensor(np.asarray(img.jpg)).permute(2, 0, 1)[None, ...] / 255.\n",
    "                    if torch.cuda.is_available():\n",
    "                        # Move to GPU to make computaions faster\n",
    "                        # print(torch.cuda.is_available())\n",
    "                        x = x.cuda()\n",
    "                    brisque_index: torch.Tensor = piq.brisque(x, data_range=1., reduction='none')\n",
    "\n",
    "                    BRISQUE_i.append(brisque_index.item())\n",
    "                except Exception as e:\n",
    "                    print(f'Error in PyTorch with image {ImageId}\\n')\n",
    "                    print(e)\n",
    "                    BRISQUE_i.append(np.nan)\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                del x\n",
    "\n",
    "        else:  # not an image\n",
    "            print(f'{fileName} is not a jpg')\n",
    "            missing_images.append(fileName)\n",
    "            Focus.append(np.nan)\n",
    "            GradientMax.append(np.nan)\n",
    "            GradientSTD.append(np.nan)\n",
    "            Colour1.append(np.nan)\n",
    "            Colour2.append(np.nan)\n",
    "            Colour3.append(np.nan)\n",
    "            Colour4.append(np.nan)\n",
    "            Colour5.append(np.nan)\n",
    "            BRISQUE_i.append(np.nan)\n",
    "            \n",
    "        f.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33735655-7e4a-432e-a6b8-2c530478390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resolution\n",
    "dpxdx = (df['px1'] - df['px0']) / (df['Cote1'] - df['Cote0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97adb7f-3476-4cc5-ad07-499d1d492a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
